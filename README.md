# Проект: Система анализа данных должников

## Описание проекта

Этот проект представляет собой систему для сбора, обработки и анализа данных о должниках с использованием Telegram-ботов и парсеров различных онлайн-сервисов. Проект включает два Telegram-бота, которые взаимодействуют с пользователями, а также набор парсеров, которые собирают данные с внешних источников. Данные сохраняются в базе SQLite, а результаты обрабатываются с использованием ИИ для формирования портрета должника.

## Логика работы проекта

1. **Общая архитектура**:
   - Проект состоит из двух Telegram-ботов (`main.py` и `main_arbitr_efrsb.py`), которые предоставляют интерфейсы для пользователей.
   - В директории `parsers` находятся скрипты для парсинга данных с различных сервисов, таких как ЕФРСБ, Кад.арбитр, ГИБДД, Реестр залогов и других.
   - Данные хранятся в базе данных SQLite (`debtors.db`), с регулярным созданием резервных копий в директории `backups`.
   - Настройки окружения (токены, URL-адреса сервисов) задаются через файл `.env` (пример: `example.env`).
   - Системный промпт для ИИ-анализа хранится в `system_prompt.txt`.

2. **Работа бота `main.py`**:
   - Бот предоставляет интерфейс для создания портрета должника на основе данных, введенных пользователем (ИНН, ФИО, VIN, СТС, ГРЗ) или загруженного Excel-файла (`Пример.xlsx`).
   - Пользователь может:
     - Вводить данные вручную через текстовые сообщения или загружать Excel-файл.
     - Просматривать данные из базы по ИНН.
     - Редактировать записи в базе.
   - Запросы обрабатываются асинхронно через очередь (`request_queue`) с ограничением в 10 запросов.
   - Данные собираются с помощью парсеров, результаты сохраняются в `debtors.db`, и формируется текстовый портрет должника с использованием ИИ (DeepSeek через OpenAI API).
   - Регулярные задачи (ежедневные бэкапы и обновления записей) выполняются с помощью планировщика `APScheduler`. В данный момент автоматическое обновление всех записей отключено.

3. **Работа бота `main_arbitr_efrsb.py`**:
   - Этот бот специализируется на поиске информации по ИНН на сайтах ЕФРСБ и Кад.арбитр.
   - Пользователь вводит ИНН (10 или 12 цифр), запрос добавляется в очередь (`request_queue`).
   - Бот отправляет запросы к парсерам (`efrsb_parser.py`, `kad_arbitr_parser.py`) и формирует отчет в формате Markdown, включающий данные о банкротстве и судебных делах.
   - Очередь обрабатывается асинхронным воркером, с ограничением в 10 запросов.

4. **Сбор и хранение данных**:
   - Парсеры взаимодействуют с внешними сервисами через HTTP-запросы (порты 5001–5008).
   - Данные сохраняются в таблице `debtors` в базе SQLite с полями: `inn`, `fio`, `vin`, `sts`, `grz`, `gibdd_auto`, `gibdd_fines`, `efrsb`, `nsis`, `reestr_zalogov`, `notariat`, `pb_nalog`, `kad_arbitr`.
   - Логи изменений записываются в `updates_log.txt`.

5. **Обработка Excel-файлов**:
   - Бот `main.py` поддерживает загрузку Excel-файлов с колонками: ИНН, ФИО, VIN, СТС, ГРЗ.
   - Каждая строка валидируется и добавляется в очередь для обработки.
   - Результаты сохраняются в базу, а портреты должников отправляются пользователю.

6. **ИИ-анализ**:
   - В `main.py` данные из базы отправляются в DeepSeek через OpenAI API для формирования текстового портрета должника.
   - Промпт, заданный в `system_prompt.txt`, определяет формат и стиль ответа.

## Основные особенности работы Telegram-ботов

1. **Асинхронная обработка**:
   - Оба бота используют библиотеку `python-telegram-bot` с асинхронной обработкой запросов через `asyncio`.
   - Запросы пользователей добавляются в очередь (`request_queue`), которая обрабатывается воркером (`worker`).

2. **Валидация входных данных**:
   - В `main.py` данные (ИНН, ФИО, VIN, СТС, ГРЗ) проверяются с помощью регулярных выражений:
     - ИНН: 10 или 12 цифр.
     - ФИО: минимум имя и фамилия, опционально дата рождения (например, "Иванов Иван;01.01.1970").
     - VIN: 17 латинских букв и цифр.
     - СТС: формат `99АА999999`.
     - ГРЗ: формат `А123БВ 777` (кириллица).
   - В `main_arbitr_efrsb.py` валидируется только ИНН (10 или 12 цифр).

3. **Интерактивный интерфейс**:
   - В `main.py` реализован интерфейс с кнопками (`InlineKeyboardMarkup`) для выбора действий (создание портрета, просмотр данных, редактирование).
   - Поля для редактирования отображаются с пагинацией (по 8 полей на страницу).
   - В `main_arbitr_efrsb.py` интерфейс текстовый, без кнопок.

4. **Обработка ошибок**:
   - Оба бота используют механизм retry (3 попытки) для отправки сообщений при ошибках `TimedOut`.
   - Ошибки парсеров или сети логируются и возвращаются пользователю в виде сообщений.

5. **Очередь запросов**:
   - Ограничение в 10 запросов в очереди предотвращает перегрузку.
   - Пользователь получает уведомление о размере очереди и статусе обработки.

6. **Планировщик задач**:
   - В `main.py` используется `APScheduler` для:
     - Ежедневного создания бэкапов базы (`backup_db`).
     - Комментированная задача для обновления записей (`update_db_records`).

7. **Логирование**:
   - Логи записываются в консоль с помощью модуля `logging`.
   - В `main.py` изменения данных дополнительно логируются в `updates_log.txt`.

## Особенности работы парсеров

1. **Список парсеров**:
   - В директории `parsers` находятся следующие скрипты:
     - `efrsb_parser.py`: Парсер данных о банкротстве с сайта ЕФРСБ.
     - `kad_arbitr_parser.py`: Парсер судебных дел с сайта Кад.арбитр.
     - `gibdd_auto_parser.py`: Парсер истории ТС по VIN с сайта ГИБДД.
     - `gibdd_fines_parser.py`: Парсер штрафов по СТС и ГРЗ с сайта ГИБДД.
     - `nsis_parser.py`: Парсер полисов ОСАГО по VIN.
     - `pb_nalog_parser.py`: Парсер налоговых задолженностей по ИНН.
     - `reestr_zalogov_parser.py`: Парсер залогов ТС по VIN с сайта reestr-zalogov.ru.
     - `notariat_parser.py`: Парсер наследственных дел по ФИО и дате рождения.

2. **Технологии парсинга**:
   - Парсеры используют библиотеку `playwright` для эмуляции браузера и взаимодействия с веб-страницами.
   - В `reestr_zalogov_parser.py` дополнительно применяется `BeautifulSoup` для парсинга сохраненного HTML.
   - HTTP-запросы выполняются через `aiohttp` для асинхронного взаимодействия.

3. **Асинхронность и ограничения**:
   - Все парсеры работают асинхронно с использованием `asyncio`.
   - В `reestr_zalogov_parser.py` реализованы ограничения параллелизма:
     - `MAX_CONCURRENT_REQUESTS=2` для одного сервиса.
     - `GLOBAL_SEMAPHORE=10` для общего числа открытых страниц.

4. **Прокси**:
   - Парсеры поддерживают прокси, задаваемые через `.env` (`PROXY_SERVER`, `PROXY_USERNAME`, `PROXY_PASSWORD`) или JSON-запросы.
   - Прокси применяются в `playwright` через настройку контекста браузера.

5. **Обработка ошибок**:
   - Парсеры обрабатывают ошибки, такие как капчи, таймауты, HTTP-ошибки, и возвращают JSON с полем `error`.
   - В `reestr_zalogov_parser.py` предусмотрена проверка на капчу (`div.captcha`) с возвратом ошибки.

6. **Формат ответов**:
   - Парсеры возвращают JSON-ответы с полями `status` (`success`, `error`, `no_data`) и `results` или `message`.
   - Пример для `reestr_zalogov_parser.py`:
     - Успех (нет залогов): `{"status": "success", "results": {}, "vin": "..."}`.
     - Успех (есть залоги): `{"status": "found", "results": {"details": [...]}, "vin": "..."}`.
     - Ошибка: `{"status": "error", "message": "...", "vin": "..."}`.

## Установка и запуск

1. **Установка зависимостей**:
   ```bash
   pip install -r requirements.txt
   ```
   Установите браузеры для Playwright:
   ```bash
   playwright install
   ```

2. **Настройка окружения**:
   - Скопируйте `example.env` в `.env` и заполните:
   - `TELEGRAM_TOKEN`: Токен Telegram-бота.
     - `API_KEY`: Ключ для OpenAI API.
     - `PROXY_API_URL`: URL прокси для OpenAI.
     - `PROXY_SERVER`, `PROXY_USERNAME`, `PROXY_PASSWORD`: Настройки прокси для парсеров.

    
## Примечания (ОЧЕНЬ ВАЖНО!!!)

- Нужен сервер с `Xubuntu` или `Ubuntu Desktop`, так как почти все парсеры подключается к desktop версии браузера по cdp, а не в headless режиме. При запуске в headless режиме парсинг не работает, например, у `kadr arbitr` не рабоатет кнопка `Найти`, у `notariat` сайт написан на Django и выдает ошибку с crsf токеном, при отправке формы и тд. Очевидно, что графический интерфейс будет потреблять больше ресурсов, поэтому вы можете реализовать парсинг в headless режиме, возможно это легко делается и я просто что-то не понял.
- Подключение к графической оболочке происходит по протоколу `RDP`, я использовал с `Ubuntu` приложение `remmina`
- Браузер запускается командой:
    ```bash
   google-chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome_profile
   ```
- Прокси нужны для сайтов `gibdd` и сайта `reestr_zalogov`, так как они банят ip адрес сервера. Также прокси используется для `nsis`, потому что у него есть ограничение на число запросов в час, а сервис использует разные ip для проксирования.
- Мой совет для улучшений: использовать кеш контекста для более быстрой загрузки браузера и использовать 1 браузер(на данный момент каждая версия парсера открывает свое окно)
- Используемые сервисы:
    - Прокси: https://my.sx.org/
    - API Deepseek: https://console.proxyapi.ru/
    - Решение каптчи: https://2captcha.com
    - Сервер с Xubuntu(его можно выбрать при выборе ПО для сервера): https://invapi.hostkey.ru/

## Пример заполнения сервиса


**Создание сервиса**
sudo nano /etc/systemd/system/telegrambottaroold.service

```ini
[Unit]
Description=Telegram Bot
After=network.target

[Service]
User=root
WorkingDirectory=/root/telegram_bots/telegrambottaroold
ExecStart=/root/telegram_bots/telegrambottaroold/venv/bin/python3 /root/telegram_bots/telegrambottaroold/tarot_bot.py
Restart=always

[Install]
WantedBy=multi-user.target
```